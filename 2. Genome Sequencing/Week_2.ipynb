{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: Solve the Eulerian Cycle Problem.\n",
    "\n",
    "Input: The adjacency list of an Eulerian directed graph.  \n",
    "Output: An Eulerian cycle in this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from typing import Dict, List\n",
    "from collections import defaultdict\n",
    "\n",
    "def build_graph(text: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Builds a graph from a list of strings representing edges.\n",
    "\n",
    "    Args:\n",
    "        text: A list of strings, where each string represents an edge in the graph\n",
    "              in the format \"source_node: destination_node1 destination_node2 ...\".\n",
    "\n",
    "    Returns:\n",
    "        A defaultdict with keys as the source nodes and values as lists of destination nodes.\n",
    "    \"\"\"\n",
    "    lines = [line.strip().split(': ')  for line in text]\n",
    "    edges = {\n",
    "        line[0]: line[1].split(' ')\n",
    "        for line in lines\n",
    "    }\n",
    "    return defaultdict(list, edges)\n",
    "\n",
    "def display_cycle(cycle: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Formats a list of nodes into a string representation of an Eulerian cycle.\n",
    "\n",
    "    Args:\n",
    "        cycle: A list of strings representing the nodes visited in an Eulerian cycle.\n",
    "\n",
    "    Returns:\n",
    "        A string representation of the Eulerian cycle in the format \"node1 node2 ... node1\".\n",
    "    \"\"\"\n",
    "    return ' '.join(map(str, cycle))\n",
    "\n",
    "\n",
    "\n",
    "from random import choice\n",
    "from typing import Dict, List\n",
    "\n",
    "def find_eulerian_cycle(string_map: Dict[str, List[str]]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Finds an Eulerian cycle in a graph represented by a dictionary.\n",
    "\n",
    "    Args:\n",
    "        string_map (Dict[str, List[str]]): A dictionary representing the graph where each key is a node and its value is a list of connected nodes.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of nodes representing the Eulerian cycle.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    result = []  # Stores the Eulerian cycle\n",
    "    start = choice(list(string_map.keys()))  # Randomly choose a starting node\n",
    "    stack = [start]  # Initialize the stack with the starting node\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        current = stack[-1]  # Get the current node from the top of the stack\n",
    "\n",
    "        if len(string_map[current]) == 0:\n",
    "            # If there are no more unvisited neighbors for the current node,\n",
    "            # remove it from the stack and prepend it to the result\n",
    "            result.insert(0, stack.pop())\n",
    "        else:\n",
    "            # Otherwise, choose a neighbor of the current node,\n",
    "            # remove it from the list of neighbors, and push it onto the stack\n",
    "            stack.append(string_map[current].pop())\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_path(cycle, graph):\n",
    "    \"\"\"\n",
    "    Checks if a given cycle traverses all edges in the graph.\n",
    "\n",
    "    Args:\n",
    "        cycle: A list of strings representing the nodes visited in a cycle.\n",
    "        graph: A dictionary with keys as nodes and values as lists of neighboring nodes.\n",
    "\n",
    "    Returns:\n",
    "        A boolean value indicating if the cycle traverses all edges in the graph.\n",
    "    \"\"\"\n",
    "    # Get all edges in the graph\n",
    "    edges = [\n",
    "        (start, end)\n",
    "        for start, ends in graph.items()\n",
    "        for end in ends\n",
    "    ]\n",
    "    # Get all edges in the cycle\n",
    "    cycle_ = list(zip(cycle[:-1], cycle[1:]))\n",
    "    # Compare the sets of edges and cycle edges\n",
    "    return sorted(edges) == sorted(cycle_)\n",
    "\n",
    "\n",
    "def is_eulerian(cycle):\n",
    "    \"\"\"\n",
    "    Checks if a given cycle is an Eulerian cycle.\n",
    "\n",
    "    Args:\n",
    "        cycle: A list of strings representing the nodes visited in a cycle.\n",
    "\n",
    "    Returns:\n",
    "        A boolean value indicating if the cycle is an Eulerian cycle.\n",
    "    \"\"\"\n",
    "    # Get all edges in the cycle\n",
    "    cycle_ = list(zip(cycle[:-1], cycle[1:]))\n",
    "    # Compare the sets of cycle edges and unique cycle edges\n",
    "    return sorted(list(set(cycle_))) == sorted(cycle_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 2 1 0 3 2 6 8 7 9 6 5\n"
     ]
    }
   ],
   "source": [
    "sample_input = [\n",
    "    '0: 3',\n",
    "    '1: 0',\n",
    "    '2: 1 6',\n",
    "    '3: 2',\n",
    "    '4: 2',\n",
    "    '5: 4',\n",
    "    '6: 5 8',\n",
    "    '7: 9',\n",
    "    '8: 7',\n",
    "    '9: 6',\n",
    "]\n",
    "\n",
    "sample_output = '6 8 7 9 6 5 4 2 1 0 3 2 6' # could be different\n",
    "\n",
    "graph = build_graph(sample_input)\n",
    "cycle = find_eulerian_cycle(graph)\n",
    "assert cycle[0] == cycle[-1]\n",
    "assert is_eulerian(cycle)\n",
    "# assert is_path(cycle, graph)\n",
    "print(display_cycle(cycle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = 'dataset_203_2'\n",
    "with open(f'data/{input_filename}.txt', 'r') as input_file:\n",
    "    test_input = input_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = build_graph(test_input)\n",
    "cycle = find_eulerian_cycle(graph)\n",
    "assert cycle[0] == cycle[-1]\n",
    "assert is_eulerian(cycle)\n",
    "# assert is_path(cycle, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'submission_' + '_'.join(input_filename.split('_')[1:])\n",
    "with open(f'data/{output_filename}.txt', 'w') as output_file:\n",
    "    output_file.write(display_cycle(cycle))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: Solve the Eulerian Path Problem.\n",
    "\n",
    "Input: The adjacency list of a directed graph that has an Eulerian path.  \n",
    "Output: An Eulerian path in this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import reduce\n",
    "# from operator import add\n",
    "# from collections import Counter\n",
    "# from typing import Dict, List\n",
    "\n",
    "\n",
    "# def find_eulerian_path(graph):\n",
    "#     \"\"\"\n",
    "#     Finds an Eulerian path in a graph represented as a dictionary of edges.\n",
    "\n",
    "#     Args:\n",
    "#         graph: A dictionary with keys as nodes and values as lists of neighboring nodes.\n",
    "\n",
    "#     Returns:\n",
    "#         A list of strings representing the nodes visited in the Eulerian path.\n",
    "#     \"\"\"\n",
    "#     # Ensure every node appears as a key in the graph dictionary\n",
    "#     for node in set(sum(graph.values(), [])):\n",
    "#         if node not in graph:\n",
    "#             graph[node] = []\n",
    "\n",
    "#     # Determine if the graph has an Eulerian path\n",
    "#     in_degrees = {node: 0 for node in graph}\n",
    "#     out_degrees = {node: len(neighbors) for node, neighbors in graph.items()}\n",
    "#     for node in graph:\n",
    "#         in_degrees[node] = sum(1 for neighbors in graph.values() if node in neighbors)\n",
    "#     start_node, end_node = None, None\n",
    "#     for node in graph:\n",
    "#         delta = out_degrees[node] - in_degrees[node]\n",
    "#         if delta == 1 and not start_node:\n",
    "#             start_node = node\n",
    "#         elif delta == -1 and not end_node:\n",
    "#             end_node = node\n",
    "#         elif delta != 0:\n",
    "#             return None\n",
    "\n",
    "#     # If an Eulerian path exists, find it\n",
    "#     path = []\n",
    "#     stack = [start_node]\n",
    "#     while stack:\n",
    "#         node = stack[-1]\n",
    "#         if graph[node]:\n",
    "#             stack.append(graph[node].pop(0))\n",
    "#         else:\n",
    "#             path.append(stack.pop())\n",
    "#     path.reverse()\n",
    "#     if path[0] != start_node or path[-1] != end_node:\n",
    "#         return None\n",
    "#     return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import deque, Counter\n",
    "\n",
    "# def find_eulerian_path(edges):\n",
    "#     \"\"\"\n",
    "#     Finds an Eulerian path in a directed graph represented as an adjacency dictionary.\n",
    "\n",
    "#     Args:\n",
    "#         edges (dict): Adjacency dictionary representing the directed graph.\n",
    "\n",
    "#     Returns:\n",
    "#         list: List of nodes representing the Eulerian path.\n",
    "#     \"\"\"\n",
    "#     in_nodes = list(edges.keys())\n",
    "#     out_nodes = sum(edges.values(), [])  # Flatten the list of outgoing nodes\n",
    "#     in_degrees = Counter(out_nodes)\n",
    "#     out_degrees = Counter({key: len(value) for key, value in edges.items()})\n",
    "#     start = end = None\n",
    "\n",
    "#     # Find start and end nodes based on the differences in degrees\n",
    "#     for node in set(out_nodes + in_nodes):\n",
    "#         difference = out_degrees[node] - in_degrees[node]\n",
    "#         if difference > 0:\n",
    "#             start = node\n",
    "#         if difference < 0:\n",
    "#             end = node\n",
    "\n",
    "#     if not start or not end:\n",
    "#         return []\n",
    "\n",
    "#     # Create an augmented graph with an additional edge from end to start\n",
    "#     augmented_edges = {end: [start], **edges}\n",
    "\n",
    "#     # Find Eulerian cycle in the augmented graph\n",
    "#     cycle = find_eulerian_cycle(augmented_edges)\n",
    "\n",
    "#     # Rotate the cycle to start at the original end node\n",
    "#     path = deque(cycle[:-1])\n",
    "#     path.rotate(-1 - path.index(end))\n",
    "\n",
    "#     return list(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def find_eulerian_path(string_map: Dict[str, List[str]]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Find an Eulerian path in a given string map.\n",
    "\n",
    "    Args:\n",
    "        string_map: A dictionary representing the adjacency list of the graph.\n",
    "\n",
    "    Returns:\n",
    "        A list representing the Eulerian path.\n",
    "\n",
    "    Algorithm:\n",
    "    1. Initialize an empty list 'result' to store the Eulerian path.\n",
    "    2. Choose a starting vertex 'start' using the 'get_start' function.\n",
    "    3. Initialize a stack with 'start' as the only element.\n",
    "    4. While the stack is not empty:\n",
    "        a. Set 'current' as the top element of the stack.\n",
    "        b. If 'current' has no outgoing edges:\n",
    "            i. Remove 'current' from the stack and insert it at the beginning of 'result'.\n",
    "           ii. Otherwise:\n",
    "            i. Push the next vertex from 'current' to the stack.\n",
    "    5. Return the 'result' list representing the Eulerian path.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    start = get_start(string_map)\n",
    "    stack = [start]\n",
    "    while len(stack) > 0:\n",
    "        current = stack[-1]\n",
    "        if len(string_map[current]) == 0:\n",
    "            result.insert(0, stack.pop())\n",
    "        else:\n",
    "            stack.append(string_map[current].pop())\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_start(string_map: Dict[str, List[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Find the starting vertex for an Eulerian path in a given string map.\n",
    "\n",
    "    Args:\n",
    "        string_map: A dictionary representing the adjacency list of the graph.\n",
    "\n",
    "    Returns:\n",
    "        A string representing the starting vertex.\n",
    "\n",
    "    Algorithm:\n",
    "    1. Initialize an empty dictionary 'result' to store the vertex information.\n",
    "    2. Iterate over the vertices in 'string_map':\n",
    "        a. If the vertex is not in 'result' or has an incomplete count:\n",
    "            i. Initialize the vertex in 'result' with [0, 0] count.\n",
    "        b. Increment the outgoing count of the vertex in 'result'.\n",
    "        c. For each outgoing edge:\n",
    "            i. If the edge is not in 'result' or has an incomplete count:\n",
    "                - Initialize the edge in 'result' with [0, 0] count.\n",
    "            ii. Increment the incoming count of the edge in 'result'.\n",
    "    3. Iterate over the vertices and their counts in 'result':\n",
    "        a. If the outgoing count of a vertex is greater than the incoming count, return the vertex.\n",
    "    4. Return the first vertex from 'result' if no suitable starting vertex is found.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for vertex, edges in string_map.items():\n",
    "        if vertex not in result or len(result[vertex]) != 2:\n",
    "            result[vertex] = [0, 0]\n",
    "        result[vertex][0] = len(edges)\n",
    "        for edge in edges:\n",
    "            if edge not in result or len(result[edge]) != 2:\n",
    "                result[edge] = [0, 0]\n",
    "            result[edge][1] += 1\n",
    "    for vertex, counts in result.items():\n",
    "        if counts[0] > counts[1]:\n",
    "            return vertex\n",
    "    return list(result.keys())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 7 8 9 6 3 0 2 1 3 4\n"
     ]
    }
   ],
   "source": [
    "sample_input = [\n",
    "    '0: 2',\n",
    "    '1: 3',\n",
    "    '2: 1',\n",
    "    '3: 0 4',\n",
    "    '6: 3 7',\n",
    "    '7: 8',\n",
    "    '8: 9',\n",
    "    '9: 6',\n",
    "]\n",
    "\n",
    "graph = build_graph(sample_input)\n",
    "path = find_eulerian_path(graph)  \n",
    "print(display_cycle(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = 'dataset_203_6'\n",
    "with open(f'data/{input_filename}.txt', 'r') as input_file:\n",
    "    test_input = input_file.readlines()\n",
    "\n",
    "graph = build_graph(test_input)\n",
    "path = find_eulerian_path(graph)\n",
    "\n",
    "output_filename = 'submission_' + '_'.join(input_filename.split('_')[1:])\n",
    "with open(f'data/{output_filename}.txt', 'w') as output_file:\n",
    "    output_file.write(display_cycle(path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: Solve the String Reconstruction Problem.\n",
    "\n",
    "Input: An integer k followed by a list of k-mers Patterns.  \n",
    "Output: A string Text with k-mer composition equal to Patterns. (If multiple answers exist, you may return any one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Week_1.ipynb \n",
    "\n",
    "def path_to_genome(path):\n",
    "    \"\"\"\n",
    "    Constructs a genome sequence from a given path.\n",
    "\n",
    "    Args:\n",
    "        path (list): A list of strings representing a path of kmers.\n",
    "\n",
    "    Returns:\n",
    "        str: The constructed genome sequence.\n",
    "\n",
    "    Example:\n",
    "        >>> path_to_genome(['AC', 'CT', 'TT'])\n",
    "        'ACTT'\n",
    "    \"\"\"\n",
    "    genome = path[0]\n",
    "    for kmer in path[1:]:\n",
    "        genome += kmer[-1]\n",
    "    return genome\n",
    "     \n",
    "\n",
    "def prefix(kmer):\n",
    "    \"\"\"\n",
    "    Returns the prefix of a k-mer.\n",
    "\n",
    "    Args:\n",
    "        kmer: A string representing a k-mer.\n",
    "\n",
    "    Returns:\n",
    "        The prefix of the input k-mer, which is the substring of the k-mer\n",
    "        from the first character up to the second-to-last character.\n",
    "    \"\"\"\n",
    "    return kmer[:-1]\n",
    "\n",
    "\n",
    "def suffix(kmer):\n",
    "    \"\"\"\n",
    "    Returns the suffix of a k-mer.\n",
    "\n",
    "    Args:\n",
    "        kmer: A string representing a k-mer.\n",
    "\n",
    "    Returns:\n",
    "        The suffix of the input k-mer, which is the substring of the k-mer\n",
    "        from the second character up to the last character.\n",
    "    \"\"\"\n",
    "    return kmer[1:]\n",
    "\n",
    "\n",
    "def debruijn_graph_from_kmers(kmers):\n",
    "    \"\"\"\n",
    "    Constructs a De Bruijn graph from a list of k-mers.\n",
    "\n",
    "    Args:\n",
    "        kmers: A list of strings representing k-mers.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary representing the De Bruijn graph, where the keys are strings\n",
    "        representing the nodes of the graph and the values are lists of strings\n",
    "        representing the outgoing edges from each node.\n",
    "    \"\"\"\n",
    "    # Create an empty dictionary with default values of empty lists.\n",
    "    edges = defaultdict(list)\n",
    "\n",
    "    # Iterate over the k-mers in the input list and add their edges to the edges dictionary.\n",
    "    for kmer in kmers:\n",
    "        edges[prefix(kmer)].append(suffix(kmer))\n",
    "\n",
    "    # Return the edges dictionary as the final De Bruijn graph representation.\n",
    "    return edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGCTTACCA\n"
     ]
    }
   ],
   "source": [
    "sample_input = [\n",
    "    'CTTA',\n",
    "    'ACCA',\n",
    "    'TACC',\n",
    "    'GGCT',\n",
    "    'GCTT',\n",
    "    'TTAC',\n",
    "]\n",
    "sample_output = 'GGCTTACCA'\n",
    "\n",
    "graph = debruijn_graph_from_kmers(sample_input)\n",
    "path = find_eulerian_path(graph)\n",
    "# print(path)\n",
    "genome = path_to_genome(path)\n",
    "print(genome)\n",
    "assert path_to_genome(path) == sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAAATGCATCATACGCTCACCCAG\n"
     ]
    }
   ],
   "source": [
    "sample_input = [\n",
    "    'AAAT',\n",
    "    'AATG',\n",
    "    'ACCC',\n",
    "    'ACGC',\n",
    "    'ATAC',\n",
    "    'ATCA',\n",
    "    'ATGC',\n",
    "    'CAAA',\n",
    "    'CACC',\n",
    "    'CATA',\n",
    "    'CATC',\n",
    "    'CCAG',\n",
    "    'CCCA',\n",
    "    'CGCT',\n",
    "    'CTCA',\n",
    "    'GCAT',\n",
    "    'GCTC',\n",
    "    'TACG',\n",
    "    'TCAC',\n",
    "    'TCAT',\n",
    "    'TGCA',\n",
    "]\n",
    "\n",
    "graph = debruijn_graph_from_kmers(sample_input)\n",
    "path = find_eulerian_path(graph)\n",
    "# print(path)\n",
    "genome = path_to_genome(path)\n",
    "print(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = 'dataset_203_7'\n",
    "with open(f'data/{input_filename}.txt', 'r') as input_file:\n",
    "    test_input = input_file.readlines()\n",
    "\n",
    "input = test_input[1].split()\n",
    "graph = debruijn_graph_from_kmers(input)\n",
    "path = find_eulerian_path(graph)\n",
    "genome = path_to_genome(path)\n",
    "\n",
    "output_filename = 'submission_' + '_'.join(input_filename.split('_')[1:])\n",
    "with open(f'data/{output_filename}.txt', 'w') as output_file:\n",
    "    output_file.write(genome)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: Solve the k-Universal Circular String Problem.\n",
    "\n",
    "Input: An integer k.  \n",
    "Output: A k-universal circular string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def binary_strings(k):\n",
    "    \"\"\"\n",
    "    Generates all possible binary strings of length k.\n",
    "\n",
    "    Args:\n",
    "        k (int): The length of binary strings.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of binary strings sorted in lexicographic order.\n",
    "    \"\"\"\n",
    "    kmers_ = product('01', repeat=k)\n",
    "    kmers = [''.join(combo) for combo in kmers_]\n",
    "    return sorted(kmers)\n",
    "\n",
    "def universal_circular_string(k):\n",
    "    \"\"\"\n",
    "    Solves the k-Universal Circular String Problem.\n",
    "\n",
    "    Args:\n",
    "        k (int): The length of k-mers.\n",
    "\n",
    "    Returns:\n",
    "        str: A k-universal circular string.\n",
    "\n",
    "    Example:\n",
    "        >>> universal_circular_string(3)\n",
    "        '00111010'\n",
    "    \"\"\"\n",
    "    kmers = binary_strings(k)\n",
    "    graph = debruijn_graph_from_kmers(kmers)\n",
    "    cycle = find_eulerian_cycle(graph)\n",
    "    genome = path_to_genome(cycle[:-(k-1)])\n",
    "    return genome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1101111001010000'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_k = 4\n",
    "universal_circular_string(sample_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = 'dataset_203_11'\n",
    "with open(f'data/{input_filename}.txt', 'r') as input_file:\n",
    "    test_input = input_file.readlines()\n",
    "    test_k = int(test_input[0].strip())\n",
    "\n",
    "result = universal_circular_string(test_k)\n",
    "\n",
    "output_filename = 'submission_' + '_'.join(input_filename.split('_')[1:])\n",
    "with open(f'data/{output_filename}.txt', 'w') as output_file:\n",
    "    output_file.write(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Reconstruction from Read-Pairs Problem: Reconstruct a string from its paired composition.\n",
    "\n",
    "Input: A collection of paired k-mers PairedReads and an integer d.  \n",
    "Output: A string Text with (k,d)-mer composition equal to PairedReads (if such a string exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired k-mers:\n",
      "(AAT|CAT) (ATG|ATG) (ATG|ATG) (CAT|GAT) (CCA|GGA) (GCC|GGG) (GGG|GTT) (TAA|CCA) (TGC|TGG) (TGG|TGT)\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def paired_composition(k: int, d: int, text: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Generates a list of paired k-mers from a given text.\n",
    "\n",
    "    Args:\n",
    "        k (int): Length of each k-mer.\n",
    "        d (int): Distance between the two k-mers in each pair.\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, str]]: List of paired k-mers.\n",
    "    \"\"\"\n",
    "    kdmers = []\n",
    "    for i in range(len(text) - 2 * k - d + 1):\n",
    "        kdmers.append((text[i:i+k], text[i+k+d:i+2*k+d]))\n",
    "    return sorted(kdmers)\n",
    "\n",
    "\n",
    "def display_kdmers(kdmers: List[Tuple[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Displays the paired k-mers in a formatted string.\n",
    "\n",
    "    Args:\n",
    "        kdmers (List[Tuple[str, str]]): List of paired k-mers.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted string representation of paired k-mers.\n",
    "    \"\"\"\n",
    "    return ' '.join(map(lambda x: f'({x[0]}|{x[1]})', kdmers))\n",
    "\n",
    "k = 3\n",
    "d = 2\n",
    "text = 'TAATGCCATGGGATGTT'\n",
    "kdmers = paired_composition(k, d, text)\n",
    "display = display_kdmers(kdmers)\n",
    "\n",
    "print(\"Paired k-mers:\")\n",
    "print(display)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Challenge: Solve the String Reconstruction from Read-Pairs Problem.\n",
    "\n",
    "Input: Integers k and d followed by a collection of paired k-mers PairedReads.  \n",
    "Output: A string Text with (k, d)-mer composition equal to PairedReads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_bruijn_paired_kmers(pairs: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Construct a de Bruijn graph from paired k-mers.\n",
    "\n",
    "    Args:\n",
    "        pairs: A list of paired k-mers represented as strings.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary representing the de Bruijn graph.\n",
    "\n",
    "    Algorithm:\n",
    "    1. Create a new list 'processed_pairs' to store the processed paired k-mers.\n",
    "    2. Iterate over each pair in 'pairs':\n",
    "        a. Strip the pair of leading/trailing whitespace and split it using '|' separator.\n",
    "        b. Append the resulting pair to 'processed_pairs'.\n",
    "    3. Initialize an empty defaultdict 'kmer_map' to store the graph.\n",
    "    4. For each pair of k-mers in 'new_pairs':\n",
    "        a. Create the prefix by concatenating the first k-1 characters of each k-mer with a '|' separator.\n",
    "        b. Create the suffix by concatenating the last k-1 characters of each k-mer with a '|' separator.\n",
    "        c. Append the suffix to the list associated with the prefix in 'kmer_map'.\n",
    "    5. Return the 'kmer_map' dictionary representing the de Bruijn graph.\n",
    "    \"\"\"\n",
    "    processed_pairs = []\n",
    "    for pair in pairs:\n",
    "        processed_pairs.append(pair.strip().split(\"|\"))\n",
    "\n",
    "    kmer_map = defaultdict(list)\n",
    "    for kmer_pair in processed_pairs:\n",
    "        prefix = \"{}|{}\".format(kmer_pair[0][:-1], kmer_pair[1][:-1])\n",
    "        suffix = \"{}|{}\".format(kmer_pair[0][1:], kmer_pair[1][1:])\n",
    "        kmer_map[prefix].append(suffix)\n",
    "\n",
    "    return kmer_map\n",
    "\n",
    "\n",
    "def paired_genome_path(pairs: List[str], k: int, d: int) -> str:\n",
    "    \"\"\"\n",
    "    Construct a paired genome path from a list of paired k-mers.\n",
    "\n",
    "    Args:\n",
    "        pairs: A list of paired k-mers represented as strings.\n",
    "        k: The length of each k-mer.\n",
    "        d: The overlap between adjacent k-mers.\n",
    "\n",
    "    Returns:\n",
    "        A string representing the paired genome path.\n",
    "\n",
    "    Algorithm:\n",
    "    1. Determine the total length 'n' of the paired k-mers.\n",
    "    2. Initialize a list 'result' with '*' characters of length 'k + k + n - 1'.\n",
    "    3. Set 'l' as 'k - 1'.\n",
    "    4. For each pair of k-mers with index 'i':\n",
    "        a. Split the pair into prefix and suffix using the '|' separator.\n",
    "        b. Calculate the start position 's2' for the suffix in 'result'.\n",
    "        c. Replace the characters from 'i' to 'i + l' in 'result' with the characters of the prefix.\n",
    "        d. Replace the characters from 's2' to 's2 + l' in 'result' with the characters of the suffix.\n",
    "    5. Return the concatenated string from 'result' representing the paired genome path.\n",
    "    \"\"\"\n",
    "    n = len(pairs)\n",
    "    result = ['*'] * (k + k + n - 1)\n",
    "    l = k - 1\n",
    "    for i, pair in enumerate(pairs):\n",
    "        prefix, suffix = pair.split('|')\n",
    "        s2 = i + k + d\n",
    "        result[i:i + l] = list(prefix)\n",
    "        result[s2:s2 + l] = list(suffix)\n",
    "    return \"\".join(result)\n",
    "\n",
    "def reconstruction_from_read_pairs(pairs, k, d):\n",
    "    graph = de_bruijn_paired_kmers(pairs)\n",
    "    path = find_eulerian_path(graph)\n",
    "    return paired_genome_path(path, k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTGGTCGTGAGATGTTGA\n"
     ]
    }
   ],
   "source": [
    "sample_k = 4\n",
    "sample_d = 2\n",
    "sample_input = [\n",
    "    'GAGA|TTGA',\n",
    "    'TCGT|GATG',\n",
    "    'CGTG|ATGT',\n",
    "    'TGGT|TGAG',\n",
    "    'GTGA|TGTT',\n",
    "    'GTGG|GTGA',\n",
    "    'TGAG|GTTG',\n",
    "    'GGTC|GAGA',\n",
    "    'GTCG|AGAT',\n",
    "]\n",
    "sample_output = 'GTGGTCGTGAGATGTTGA'\n",
    "sample_result = reconstruction_from_read_pairs(sample_input, sample_k, sample_d)\n",
    "print(sample_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACTGATTCTGATACCGAAACTT\n"
     ]
    }
   ],
   "source": [
    "sample_k = 3\n",
    "sample_d = 1\n",
    "sample_input = [\n",
    "    'ACC|ATA',\n",
    "    'ACT|ATT',\n",
    "    'ATA|TGA',\n",
    "    'ATT|TGA',\n",
    "    'CAC|GAT',\n",
    "    'CCG|TAC',\n",
    "    'CGA|ACT',\n",
    "    'CTG|AGC',\n",
    "    'CTG|TTC',\n",
    "    'GAA|CTT',\n",
    "    'GAT|CTG',\n",
    "    'GAT|CTG',\n",
    "    'TAC|GAT',\n",
    "    'TCT|AAG',\n",
    "    'TGA|GCT',\n",
    "    'TGA|TCT',\n",
    "    'TTC|GAA',\n",
    "]\n",
    "sample_result = reconstruction_from_read_pairs(sample_input, sample_k, sample_d)\n",
    "print(sample_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = 'dataset_204_16'\n",
    "with open(f'data/{input_filename}.txt', 'r') as input_file:\n",
    "    test_input = input_file.readlines()\n",
    "    test_params = test_input[0].strip().split(' ')\n",
    "    test_k = int(test_params[0])\n",
    "    test_d = int(test_params[1])\n",
    "    test_pairs = test_input[1].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = reconstruction_from_read_pairs(test_pairs, test_k, test_d)\n",
    "\n",
    "output_filename = 'submission_' + '_'.join(input_filename.split('_')[1:])\n",
    "with open(f'data/{output_filename}.txt', 'w') as output_file:\n",
    "    output_file.write(test_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contig Generation Problem: Generate the contigs from a collection of reads (with imperfect coverage).\n",
    "\n",
    "Input: A collection of k-mers Patterns.  \n",
    "Output: All contigs in DeBruijn(Patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List, Dict\n",
    "\n",
    "def get_incoming_edges(graph: Dict[str, List[str]]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Get the incoming edges for each node in the graph.\n",
    "\n",
    "    Args:\n",
    "        graph: A dictionary representing the adjacency list of the graph.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where each node is a key and its incoming edges are values.\n",
    "\n",
    "    Algorithm:\n",
    "    1. Initialize an empty defaultdict 'ins' to store the incoming edges.\n",
    "    2. Iterate over each key-value pair in the graph:\n",
    "        a. For each outgoing edge in the value list, add the key as an incoming edge in the 'ins' dictionary.\n",
    "    3. Return the 'ins' dictionary containing the incoming edges.\n",
    "    \"\"\"\n",
    "    ins = defaultdict(list)\n",
    "    for kmer, outs in graph.items():\n",
    "        for out in outs:\n",
    "            ins[out].append(kmer)\n",
    "    return ins\n",
    "\n",
    "\n",
    "def is_one_in_one_out(kmer: str, ins: Dict[str, List[str]], outs: Dict[str, List[str]]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a k-mer has exactly one incoming edge and one outgoing edge.\n",
    "\n",
    "    Args:\n",
    "        kmer: A k-mer string.\n",
    "        ins: A dictionary representing the incoming edges for each node.\n",
    "        outs: A dictionary representing the outgoing edges for each node.\n",
    "\n",
    "    Returns:\n",
    "        A boolean indicating if the k-mer has one incoming edge and one outgoing edge.\n",
    "\n",
    "    Algorithm:\n",
    "    1. Check if the length of the incoming edges list and outgoing edges list for the k-mer is equal to 1.\n",
    "    2. Return True if the condition is satisfied, otherwise False.\n",
    "    \"\"\"\n",
    "    return len(ins[kmer]) == len(outs[kmer]) == 1\n",
    "\n",
    "\n",
    "def generate_contigs(kmers: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate contigs from a list of k-mers.\n",
    "\n",
    "    Args:\n",
    "        kmers: A list of k-mers represented as strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of contigs.\n",
    "\n",
    "    Algorithm:\n",
    "    1. Initialize an empty list 'result' to store the generated contigs.\n",
    "    2. Construct the De Bruijn graph from the given list of k-mers.\n",
    "    3. Get the incoming edges for each node in the graph.\n",
    "    4. Iterate over each key in the graph:\n",
    "        a. Get the outgoing edges for the current k-mer.\n",
    "        b. If the current k-mer does not have exactly one incoming and one outgoing edge:\n",
    "            - Create a list of contigs containing the current k-mer repeated for the number of outgoing edges.\n",
    "            - For each outgoing edge, extend the contig by traversing the graph until the current node has\n",
    "              more than one incoming or outgoing edge.\n",
    "        c. Append the generated contigs to the 'result' list.\n",
    "    5. Return the 'result' list of contigs.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    outs_graph = debruijn_graph_from_kmers(kmers)\n",
    "    ins_graph = get_incoming_edges(outs_graph)\n",
    "    for kmer in list(outs_graph.keys()):\n",
    "        outs = outs_graph[kmer]\n",
    "        if not is_one_in_one_out(kmer, ins_graph, outs_graph):\n",
    "            contigs = [kmer] * len(outs)\n",
    "            for i, out in enumerate(outs):\n",
    "                current = out\n",
    "                contigs[i] += current[-1]\n",
    "                while is_one_in_one_out(current, ins_graph, outs_graph):\n",
    "                    current = outs_graph[current][0]\n",
    "                    contigs[i] += current[-1]\n",
    "            result += contigs\n",
    "    return result\n",
    "\n",
    "def display_contigs(contigs: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Display contigs as a string.\n",
    "\n",
    "    vbnet\n",
    "    Copy code\n",
    "    Args:\n",
    "        contigs: A list of contigs.\n",
    "\n",
    "    Returns:\n",
    "        A string representation of contigs.\n",
    "    \"\"\"\n",
    "    return ' '.join(contigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = [\n",
    "    'ATG',\n",
    "    'ATG',\n",
    "    'TGT',\n",
    "    'TGG',\n",
    "    'CAT',\n",
    "    'GGA',\n",
    "    'GAT',\n",
    "    'AGA',\n",
    "]\n",
    "sample_output = 'AGA ATG ATG CAT GAT TGGA TGT'\n",
    "assert sample_output == display_contigs(sorted(generate_contigs(sample_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = 'dataset_205_5'\n",
    "with open(f'data/{input_filename}.txt', 'r') as input_file:\n",
    "    test_input = input_file.read().split()\n",
    "\n",
    "contigs = generate_contigs(test_input)\n",
    "\n",
    "output_filename = 'submission_' + '_'.join(input_filename.split('_')[1:])\n",
    "with open(f'data/{output_filename}.txt', 'w') as output_file:\n",
    "    output_file.write(display_contigs(contigs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Carsonella ruddii\n",
    "\n",
    "Given a collection of simulated error-free read-pairs (with exact distance d = 1000 between reads of length k = 120 within a read-pair), use the paired de Bruijn graph to reconstruct the Carsonella ruddii genome. Compare this assembly to the assembly obtained from the classic de Bruijn graph (i.e., when all we know is the reads themselves and do not know the distance between paired reads) in order to better appreciate the benefits of read-pairs. For each k, what is the minimum value of d needed to enable reconstruction of the entire Carsonella ruddii genome from its (k,d)-mer composition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 120\n",
    "d = 1000\n",
    "\n",
    "with open(f'data/reads.txt', 'r') as reads_file:\n",
    "    read_pairs = reads_file.readlines()\n",
    "\n",
    "result = reconstruction_from_read_pairs(read_pairs, k, d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
